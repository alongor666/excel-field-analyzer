#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº¤äº’å¼Excelå­—æ®µåˆ†æå™¨ - Claude Codeä¸“ç”¨
æ”¯æŒæœªçŸ¥å­—æ®µçš„äº¤äº’å¼å­¦ä¹ 
"""

import sys
from pathlib import Path
from analyzer import ExcelAnalyzer


def analyze_with_learning(xlsx_path: str, output_dir: str = './analysis_output', topn: int = 10):
    """
    å¸¦äº¤äº’å¼å­¦ä¹ çš„åˆ†ææµç¨‹

    Args:
        xlsx_path: Excelæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        topn: Topå€¼æ˜¾ç¤ºæ•°é‡
    """

    xlsx_path = Path(xlsx_path)
    if not xlsx_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {xlsx_path}")
        return None

    print(f"\n{'='*60}")
    print(f"ğŸ“Š Excelå­—æ®µåˆ†æå·¥å…· v2.0")
    print(f"{'='*60}\n")

    # åˆ›å»ºåˆ†æå™¨
    analyzer = ExcelAnalyzer()

    # ç¬¬ä¸€æ¬¡åˆ†æ
    print(f"ğŸ” æ­£åœ¨åˆ†æ: {xlsx_path.name}")
    result = analyzer.analyze_excel(str(xlsx_path), output_dir, topn)

    if not result['success']:
        print(f"âŒ åˆ†æå¤±è´¥: {result['message']}")
        return None

    # æ£€æŸ¥æœªçŸ¥å­—æ®µ
    unknown_fields = result.get('unknown_fields', [])

    if unknown_fields:
        print(f"\n{'='*60}")
        print(f"ğŸ” å‘ç° {len(unknown_fields)} ä¸ªæœªçŸ¥å­—æ®µ")
        print(f"{'='*60}")

        for idx, field in enumerate(unknown_fields, 1):
            print(f"\n{idx}. {field}")

        print(f"\n{'='*60}")
        response = input("æ˜¯å¦ä¸ºè¿™äº›å­—æ®µåˆ›å»ºæ˜ å°„ï¼Ÿ(y/n): ").strip().lower()

        if response == 'y':
            print(f"\nå¼€å§‹å­¦ä¹ æ–°å­—æ®µ...\n")

            for cn_field in unknown_fields:
                print(f"{'â”€'*60}")
                print(f"å­—æ®µ: {cn_field}")
                print(f"{'â”€'*60}")

                # æ™ºèƒ½å»ºè®®è‹±æ–‡å
                suggested_en = suggest_english_name(cn_field)
                en_name_input = input(f"è‹±æ–‡å­—æ®µå [å»ºè®®: {suggested_en}]: ").strip()
                en_name = en_name_input if en_name_input else suggested_en

                # é€‰æ‹©åˆ†ç»„
                print("\nä¸šåŠ¡åˆ†ç»„é€‰é¡¹:")
                groups = [
                    "finance (è´¢åŠ¡æ•°æ®: ä¿è´¹ã€èµ”æ¬¾ã€è´¹ç”¨)",
                    "vehicle (è½¦è¾†ç›¸å…³: è½¦ç‰Œã€è½¦å‹)",
                    "organization (æœºæ„ä¿¡æ¯: ä¸‰çº§æœºæ„ã€å››çº§æœºæ„)",
                    "product (äº§å“ä¿¡æ¯: é™©ç±»ã€é™©ç§)",
                    "time (æ—¶é—´æ—¥æœŸ)",
                    "flag (æ ‡è¯†å­—æ®µ: æ˜¯å¦...)",
                    "partner (åˆä½œä¼™ä¼´: 4Sé›†å›¢)",
                    "general (é€šç”¨å­—æ®µ)"
                ]
                for i, g in enumerate(groups, 1):
                    print(f"  {i}. {g}")

                group_choice = input("\né€‰æ‹©åˆ†ç»„ [1-8, é»˜è®¤8]: ").strip()
                group_map = {
                    '1': 'finance', '2': 'vehicle', '3': 'organization',
                    '4': 'product', '5': 'time', '6': 'flag',
                    '7': 'partner', '8': 'general', '': 'general'
                }
                group = group_map.get(group_choice, 'general')

                # é€‰æ‹©æ•°æ®ç±»å‹
                print("\næ•°æ®ç±»å‹é€‰é¡¹:")
                print("  1. number (æ•°å€¼å‹)")
                print("  2. string (å­—ç¬¦ä¸²)")
                print("  3. datetime (æ—¶é—´æ—¥æœŸ)")

                dtype_choice = input("\né€‰æ‹©ç±»å‹ [1-3, é»˜è®¤2]: ").strip()
                dtype_map = {
                    '1': 'number', '2': 'string', '3': 'datetime', '': 'string'
                }
                dtype = dtype_map.get(dtype_choice, 'string')

                # å¯é€‰è¯´æ˜
                description = input("\nè¯´æ˜ï¼ˆå¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡ï¼‰: ").strip()

                # ä¿å­˜æ˜ å°„
                analyzer.mapping_manager.add_custom_mapping(
                    cn_field=cn_field,
                    en_name=en_name,
                    group=group,
                    dtype=dtype,
                    description=description or f"{cn_field}çš„è‡ªå®šä¹‰æ˜ å°„"
                )

                print(f"âœ… å·²ä¿å­˜: {cn_field} â†’ {en_name} ({group}, {dtype})")

            # é‡æ–°åˆ†æ
            print(f"\n{'='*60}")
            print(f"ğŸ”„ ä½¿ç”¨æ–°æ˜ å°„é‡æ–°åˆ†æ...")
            print(f"{'='*60}\n")

            # é‡æ–°åˆ›å»ºåˆ†æå™¨ä»¥åŠ è½½æ–°æ˜ å°„
            analyzer = ExcelAnalyzer()
            result = analyzer.analyze_excel(str(xlsx_path), output_dir, topn)

    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    if result['success']:
        print(f"\n{'='*60}")
        print(f"âœ… åˆ†æå®Œæˆï¼")
        print(f"{'='*60}")
        print(f"ğŸ“Š å·¥ä½œè¡¨æ•°: {len(result['sheets'])}")
        print(f"   å·¥ä½œè¡¨: {', '.join(result['sheets'])}")
        print(f"\nğŸ“ å­—æ®µç»Ÿè®¡:")
        print(f"   æ€»å­—æ®µæ•°: {result['field_stats']['total_fields']}")
        print(f"   âœ“ å·²æ˜ å°„: {result['field_stats']['mapped_count']}")
        print(f"   ? æœªçŸ¥å­—æ®µ: {result['field_stats']['unknown_count']}")

        if result['field_stats']['by_dtype']:
            print(f"\nğŸ“Š ç±»å‹åˆ†å¸ƒ:")
            for dtype, count in result['field_stats']['by_dtype'].items():
                print(f"   {dtype}: {count}")

        if result['field_stats']['by_group']:
            print(f"\nğŸ·ï¸  åˆ†ç»„åˆ†å¸ƒ:")
            for group, count in result['field_stats']['by_group'].items():
                print(f"   {group}: {count}")

        print(f"\nğŸ“„ è¾“å‡ºæ–‡ä»¶:")
        print(f"   HTMLæŠ¥å‘Š: {result['html_path']}")
        print(f"   JSONæ˜ å°„: {result['json_path']}")
        print(f"{'='*60}\n")

    return result


def suggest_english_name(cn_field: str) -> str:
    """åŸºäºä¸­æ–‡å­—æ®µåå»ºè®®è‹±æ–‡å"""
    import re

    # ç®€å•çš„æ‹¼éŸ³æ˜ å°„ï¼ˆå¯ä»¥æ‰©å±•ï¼‰
    common_words = {
        'å®¢æˆ·': 'customer',
        'ç­‰çº§': 'level',
        'æ»¡æ„åº¦': 'satisfaction',
        'è¯„åˆ†': 'score',
        'ä»£ç†': 'agent',
        'ä»£ç†å•†': 'agent',
        'é£é™©': 'risk',
        'é¢„è­¦': 'warning',
        'æ ‡è¯†': 'flag',
        'çŠ¶æ€': 'status',
        'ç±»å‹': 'type',
        'æ¥æº': 'source',
        'æ¸ é“': 'channel',
        'é‡‘é¢': 'amount',
        'æ•°é‡': 'count',
        'æ¯”ç‡': 'ratio',
        'å æ¯”': 'percentage',
        'åç§°': 'name',
        'ç¼–å·': 'code',
        'åœ°åŒº': 'region',
        'çœä»½': 'province',
        'åŸå¸‚': 'city',
    }

    # å°è¯•åŒ¹é…å¸¸è§è¯
    tokens = []
    remaining = cn_field

    for cn, en in sorted(common_words.items(), key=lambda x: len(x[0]), reverse=True):
        if cn in remaining:
            tokens.append(en)
            remaining = remaining.replace(cn, '')

    if tokens:
        return '_'.join(tokens)

    # å¦åˆ™è¿”å›ç®€å•çš„å­—æ®µå
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    clean = re.sub(r'[^\w]', '', cn_field)
    return f"field_{clean[:20]}"  # é™åˆ¶é•¿åº¦


def main():
    """ä¸»ç¨‹åº"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python interactive_analyzer.py <Excelæ–‡ä»¶è·¯å¾„> [è¾“å‡ºç›®å½•] [topn]")
        print("\nç¤ºä¾‹:")
        print("  python interactive_analyzer.py data.xlsx")
        print("  python interactive_analyzer.py data.xlsx ./output 20")
        sys.exit(1)

    xlsx_path = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else './analysis_output'
    topn = int(sys.argv[3]) if len(sys.argv) > 3 else 10

    try:
        result = analyze_with_learning(xlsx_path, output_dir, topn)
        if result and result['success']:
            sys.exit(0)
        else:
            sys.exit(1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
