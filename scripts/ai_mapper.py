#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIé©±åŠ¨çš„æ‰¹é‡å­—æ®µæ˜ å°„ç”Ÿæˆå™¨
è‡ªåŠ¨åˆ†ææœªçŸ¥å­—æ®µå¹¶ç”Ÿæˆè‹±æ–‡æ˜ å°„å»ºè®®
"""

import re
from typing import List, Dict, Any
import pandas as pd


class AIFieldMapper:
    """AIå­—æ®µæ˜ å°„ç”Ÿæˆå™¨"""

    def __init__(self):
        # è½¦é™©ä¸šåŠ¡é¢†åŸŸå…³é”®è¯æ˜ å°„
        self.keyword_patterns = {
            # æ—¶é—´ç›¸å…³
            r'æ—¶é—´|æ—¥æœŸ': ('time', 'datetime'),
            r'èµ·æœŸ|æ­¢æœŸ|ç”Ÿæ•ˆ|åˆ°æœŸ': ('time', 'datetime'),

            # æœºæ„ç›¸å…³
            r'æœºæ„|æ”¯å…¬å¸|ä¸­å¿ƒ|åˆ†å…¬å¸|è¥ä¸šéƒ¨': ('organization', 'string'),
            r'ä¸šåŠ¡å‘˜|ä»£ç†|ç»çºª': ('organization', 'string'),

            # è´¢åŠ¡ç›¸å…³
            r'ä¿è´¹|è´¹ç”¨|é‡‘é¢|èµ”æ¬¾|NCD|æŠ˜æ‰£': ('finance', 'number'),
            r'æ‰‹ç»­è´¹|ä½£é‡‘|ç¨|ä»·æ ¼': ('finance', 'number'),

            # äº§å“ç›¸å…³
            r'é™©ç§|é™©åˆ«|é™©ç±»|äº§å“': ('product', 'string'),
            r'ä¿é¢|ä¿éšœ|é™é¢': ('product', 'number'),

            # è½¦è¾†ç›¸å…³
            r'è½¦ç‰Œ|è½¦æ¶|å‘åŠ¨æœº|è½¦å‹|å‚ç‰Œ': ('vehicle', 'string'),
            r'å¨ä½|åº§ä½|æ’é‡|åŠŸç‡': ('vehicle', 'number'),

            # æ ‡è¯†ç›¸å…³
            r'^æ˜¯å¦': ('flag', 'string'),
            r'æ ‡è¯†|æ ‡å¿—|ç±»å‹': ('flag', 'string'),

            # å®¢æˆ·ç›¸å…³
            r'å®¢æˆ·|è¢«ä¿é™©äºº|æŠ•ä¿äºº|å§“å': ('general', 'string'),
            r'è¯ä»¶|èº«ä»½': ('general', 'string'),

            # ä¿å•ç›¸å…³
            r'ä¿å•å·|æ‰¹å•å·|å•å·': ('general', 'string'),
            r'ç»­ä¿|è½¬ä¿|æ–°ä¿': ('flag', 'string'),
        }

    def pinyin_convert(self, chinese: str) -> str:
        """
        ä¸­æ–‡è½¬æ‹¼éŸ³çš„ç®€åŒ–ç‰ˆæœ¬ï¼ˆåŸºäºå¸¸è§æ¨¡å¼ï¼‰
        å®é™…ä½¿ç”¨æ—¶å¯ä»¥é›†æˆpypinyinåº“è·å¾—æ›´å¥½æ•ˆæœ
        """
        # ç®€åŒ–ç‰ˆï¼šæå–å…³é”®è¯å¹¶è½¬æ¢
        mappings = {
            'æ—¶é—´': 'time',
            'æ—¥æœŸ': 'date',
            'ä¿è´¹': 'premium',
            'è´¹ç”¨': 'fee',
            'æœºæ„': 'organization',
            'æ”¯å…¬å¸': 'branch',
            'é™©ç§': 'insurance_type',
            'è½¦ç‰Œ': 'license_plate',
            'å®¢æˆ·': 'customer',
            'ä¿å•': 'policy',
            'æ‰¹å•': 'endorsement',
            'ä¸šåŠ¡å‘˜': 'agent',
            'æ˜¯å¦': 'is',
            'æ–°æ—§è½¦': 'new_old_car',
            'ç»­ä¿': 'renewal',
            'è½¬ä¿': 'transfer',
            'æ ‡è¯†': 'flag',
            'ç±»å‹': 'type',
            'é‡‘é¢': 'amount',
            'æŠ˜æ‰£': 'discount',
            'ç³»æ•°': 'coefficient',
            'èµ·æœŸ': 'start_date',
            'ç¡®è®¤': 'confirm',
            'æŠ•ä¿': 'insure',
            'è¢«ä¿é™©äºº': 'insured',
            'æŠ•ä¿äºº': 'applicant',
            'è¯ä»¶å·': 'id_number',
            'å¹´é¾„': 'age',
            'æ€§åˆ«': 'gender',
            'è½¦å‹': 'vehicle_model',
            'è½¦æ¶å·': 'vin',
            'å‘åŠ¨æœºå·': 'engine_number',
            'ä»£ç†': 'agent',
            'ç»çºª': 'broker',
            'ç­¾å•': 'signing',
            'æ‰¹æ”¹': 'endorsement',
            'ä¿é¢': 'insured_amount',
            'æ‰‹ç»­è´¹': 'commission',
            'æ¯”ä¾‹': 'ratio',
            'å«ç¨': 'tax_included',
            'ä¼˜å¾…': 'discount',
            'å¢å€¼ç¨': 'vat',
            'åº§ä½æ•°': 'seats',
            'å¨ä½': 'tonnage',
            'æ’é‡': 'displacement',
            'æ•´å¤‡è´¨é‡': 'curb_weight',
            'è´­ç½®ä»·': 'purchase_price',
            'ä½¿ç”¨å¹´é™': 'service_years',
            'ç¬”æ•°': 'count',
            'æ•°é‡': 'quantity',
            'æ¥æº': 'source',
            'æ€§è´¨': 'nature',
            'å½’å±': 'attribution',
            'åˆ†ç»„': 'group',
            'åˆ†æ®µ': 'segment',
            'ç­‰çº§': 'level',
            'è¯„åˆ†': 'score',
            'é£é™©': 'risk',
            'é«˜é€Ÿ': 'highway',
            'è´§è½¦': 'truck',
            'ç§ç±»': 'category',
            'äº¤å‰': 'cross',
            'é”€å”®': 'sales',
            'è¿‡æˆ·': 'transfer_ownership',
            'æ–°èƒ½æº': 'new_energy',
            'ç½‘çº¦è½¦': 'online_hailing',
            'å¼‚åœ°': 'non_local',
            'è¥ä¸š': 'business',
            'ä¼ä¸š': 'enterprise',
            'é›†å›¢': 'group',
            'åˆ·æ–°': 'refresh',
        }

        # å°è¯•åŒ¹é…å…³é”®è¯
        tokens = []
        remaining = chinese

        # æŒ‰é•¿åº¦é™åºæ’åˆ—ï¼Œä¼˜å…ˆåŒ¹é…é•¿è¯
        sorted_keys = sorted(mappings.keys(), key=len, reverse=True)

        for key in sorted_keys:
            if key in remaining:
                tokens.append(mappings[key])
                remaining = remaining.replace(key, '', 1)

        # âš ï¸ ä¸å†æ·»åŠ 'field'å ä½ç¬¦ï¼
        # å¦‚æœå®Œå…¨æ— æ³•è¯†åˆ«ï¼Œä½¿ç”¨æ‹¼éŸ³é¦–å­—æ¯æˆ–è¿”å›ç©ºï¼ˆç”±ä¸Šå±‚å¤„ç†ï¼‰
        if not tokens:
            # æœ€åçš„å…œåº•ï¼šè¿”å›ä¸€ä¸ªåŸºæœ¬æ ‡è¯†ï¼ˆä½†é¿å…ä½¿ç”¨'field'ï¼‰
            return 'unmapped'

        return '_'.join(tokens)

    def analyze_field(self, field_name: str, sample_values: List[Any] = None) -> Dict[str, str]:
        """
        åˆ†æå•ä¸ªå­—æ®µï¼Œç”Ÿæˆæ˜ å°„å»ºè®®ï¼ˆä¸“ä¸šæ ‡å‡†ï¼‰

        Args:
            field_name: ä¸­æ–‡å­—æ®µå
            sample_values: å­—æ®µçš„ç¤ºä¾‹æ•°æ®

        Returns:
            {'en_name': str, 'group': str, 'dtype': str, 'description': str}
        """
        # 1. æ£€æµ‹åˆ†ç»„å’ŒåŸºç¡€ç±»å‹ï¼ˆåŸºäºå…³é”®è¯ï¼‰
        group = 'general'
        dtype = 'string'

        for pattern, (grp, dt) in self.keyword_patterns.items():
            if re.search(pattern, field_name):
                group = grp
                dtype = dt
                break

        # 2. ğŸ†• ä¸“ä¸šç±»å‹æ£€æµ‹ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
        # âš ï¸ ä¿å•å·/æ‰¹å•å·/è¯ä»¶å·å¿…é¡»æ˜¯ string
        if any(keyword in field_name for keyword in ['ä¿å•å·', 'æ‰¹å•å·', 'è¯ä»¶å·', 'å•å·', 'ç¼–å·']):
            dtype = 'string'

        # âš ï¸ æ—¶é—´/æ—¥æœŸ/èµ·æœŸå¿…é¡»æ˜¯ datetime
        if any(keyword in field_name for keyword in ['æ—¶é—´', 'æ—¥æœŸ', 'èµ·æœŸ', 'æ­¢æœŸ', 'ç”Ÿæ•ˆ', 'åˆ°æœŸ']):
            dtype = 'datetime'

        # âš ï¸ "æ˜¯å¦"å­—æ®µè®¾ç½®ä¸º enum
        if field_name.startswith('æ˜¯å¦'):
            dtype = 'enum'
            group = 'flag'

        # 3. æ ·æœ¬æ•°æ®è¾…åŠ©æ¨æ–­ï¼ˆä½†ä¸èƒ½è¦†ç›–ä¸“ä¸šè§„åˆ™ï¼‰
        if sample_values and dtype not in ['datetime', 'enum']:
            non_null_values = [v for v in sample_values if pd.notna(v) and str(v).strip()]
            if non_null_values:
                try:
                    sample_str = str(non_null_values[0])
                    # åªæœ‰åœ¨æ²¡æœ‰æ˜ç¡®è§„åˆ™æ—¶æ‰å°è¯•æ¨æ–­æ•°å€¼
                    if dtype == 'string' and sample_str.replace('.', '').replace('-', '').replace(',', '').isdigit():
                        # å¦‚æœä¸æ˜¯å•å·ç±»ï¼Œå¯ä»¥è®¾ä¸ºnumber
                        if 'å·' not in field_name and 'ç¼–å·' not in field_name:
                            dtype = 'number'
                except:
                    pass

        # 4. ç”Ÿæˆè‹±æ–‡å­—æ®µå
        base_en_name = self.pinyin_convert(field_name)

        # 5. ğŸ†• æ·»åŠ ä¸“ä¸šåç¼€ï¼ˆå•ä½/æ ¼å¼æ ‡æ³¨ï¼‰
        en_name = base_en_name

        # âš ï¸ é‡‘é¢å­—æ®µæ·»åŠ  _yuan åç¼€
        if any(keyword in field_name for keyword in ['ä¿è´¹', 'è´¹ç”¨', 'é‡‘é¢', 'ä»·æ ¼', 'èµ”æ¬¾', 'æ‰‹ç»­è´¹', 'ç¨', 'è´­ç½®ä»·']):
            if dtype == 'number' and not en_name.endswith('_yuan'):
                en_name = en_name + '_yuan'

        # âš ï¸ æ¯”ä¾‹å­—æ®µæ·»åŠ  _percent åç¼€
        if 'æ¯”ä¾‹' in field_name and dtype == 'number':
            if not en_name.endswith(('_percent', '_ratio')):
                en_name = en_name + '_percent'

        # âš ï¸ ç³»æ•°/æŠ˜æ‰£å­—æ®µæ·»åŠ  _coefficient åç¼€
        if any(keyword in field_name for keyword in ['ç³»æ•°', 'æŠ˜æ‰£']) and dtype == 'number':
            if not en_name.endswith('_coefficient'):
                en_name = en_name + '_coefficient'

        # 6. ç”Ÿæˆæè¿°
        description = f"{field_name} [ç»„:{group}, ç±»å‹:{dtype}]"

        return {
            'en_name': en_name,
            'group': group,
            'dtype': dtype,
            'description': description
        }

    def batch_analyze_fields(
        self,
        unknown_fields: List[str],
        df: pd.DataFrame = None,
        sample_size: int = 100
    ) -> Dict[str, Dict[str, str]]:
        """
        æ‰¹é‡åˆ†ææœªçŸ¥å­—æ®µ

        Args:
            unknown_fields: æœªçŸ¥å­—æ®µåˆ—è¡¨
            df: åŒ…å«è¿™äº›å­—æ®µçš„DataFrameï¼ˆå¯é€‰ï¼‰
            sample_size: é‡‡æ ·æ•°é‡

        Returns:
            {field_name: mapping_dict}
        """
        mappings = {}

        for field in unknown_fields:
            # è·å–æ ·æœ¬æ•°æ®
            sample_values = None
            if df is not None and field in df.columns:
                sample_values = df[field].dropna().head(sample_size).tolist()

            # åˆ†æå­—æ®µ
            mapping = self.analyze_field(field, sample_values)
            mappings[field] = mapping

        return mappings

    def format_as_json_config(self, mappings: Dict[str, Dict[str, str]]) -> Dict[str, Any]:
        """
        å°†æ˜ å°„è½¬æ¢ä¸ºJSONé…ç½®æ ¼å¼

        Returns:
            ç¬¦åˆfield_mappings/*.jsonæ ¼å¼çš„é…ç½®
        """
        config_mappings = {}

        for cn_field, mapping in mappings.items():
            config_mappings[cn_field] = {
                'en_name': mapping['en_name'],
                'group': mapping['group'],
                'dtype': mapping['dtype'],
                'description': mapping['description']
            }

        return {
            'domain': 'auto_learned',
            'description': 'AIè‡ªåŠ¨å­¦ä¹ ç”Ÿæˆçš„å­—æ®µæ˜ å°„',
            'version': '1.0',
            'mappings': config_mappings,
            'learn_history': []
        }


if __name__ == '__main__':
    # æµ‹è¯•
    mapper = AIFieldMapper()

    test_fields = [
        'ä¿å•å·',
        'è½¦ç‰Œå·ç ',
        'ç­¾å•ä¿è´¹',
        'æ˜¯å¦ç»­ä¿',
        'æŠ•ä¿ç¡®è®¤æ—¶é—´',
        'ä¸‰çº§æœºæ„',
        'å•†ä¸šé™©ä¿è´¹'
    ]

    results = mapper.batch_analyze_fields(test_fields)

    print("AIå­—æ®µæ˜ å°„ç”Ÿæˆæµ‹è¯•:")
    print("=" * 60)
    for field, mapping in results.items():
        print(f"\n{field}:")
        print(f"  è‹±æ–‡å: {mapping['en_name']}")
        print(f"  åˆ†ç»„: {mapping['group']}")
        print(f"  ç±»å‹: {mapping['dtype']}")
        print(f"  æè¿°: {mapping['description']}")
